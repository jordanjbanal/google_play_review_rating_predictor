{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Mobile App Review Rating Predictor\r\n",
                "## Making a predictive model based on 140,000+ app reviews from the Google Play Store from 10 different categories"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Imports"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "source": [
                "import pandas as pd\r\n",
                "import re\r\n",
                "from nltk.corpus import stopwords\r\n",
                "from nltk.stem.porter import PorterStemmer\r\n",
                "from sklearn.feature_extraction.text import CountVectorizer\r\n",
                "from sklearn.model_selection import train_test_split\r\n",
                "from sklearn.naive_bayes import MultinomialNB\r\n",
                "import joblib"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Loading the dataset - trying another type of file (.tsv)\r\n",
                "##### reviews.csv == reviews.tsv"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "source": [
                "df = pd.read_csv('reviews.tsv', delimiter='\\t')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Drop null values"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "source": [
                "# Drop null values\r\n",
                "df = df.dropna(subset=['content'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Reset dataframe indexes for the future loops to work correctly"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "source": [
                "df = df.reset_index()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Cleaning the reviews and creating a corpus ready for vectorization"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "source": [
                "corpus = []\r\n",
                "\r\n",
                "# Looping through all 141460 rows in the DataFrame\r\n",
                "for i in range(0, 141460)\r\n",
                "    # Removing the special character from the reviews and replacing it with space character\r\n",
                "    review = re.sub(pattern='[^a-zA-Z]', repl=' ', string=df['content'][i])\r\n",
                "\r\n",
                "    # Converting the review into lower case character\r\n",
                "    review = review.lower()\r\n",
                "\r\n",
                "    # Tokenizing the review by words\r\n",
                "    review_words = review.split()\r\n",
                "\r\n",
                "    # Removing the stop words using nltk stopwords - remove useless English words like 'the', 'a', 'if', 'be' providing no meaning to understand of the meaning of the review\r\n",
                "    review_words = [word for word in review_words if not word in set(\r\n",
                "        stopwords.words('english'))]\r\n",
                "\r\n",
                "    # Stemming the words - reduces words like “retrieval”, “retrieved”, “retrieves” to the stem “retrieve”\r\n",
                "    ps = PorterStemmer()\r\n",
                "    review = [ps.stem(word) for word in review_words]\r\n",
                "\r\n",
                "    # Joining the stemmed words\r\n",
                "    review = ' '.join(review)\r\n",
                "\r\n",
                "    # Creating a corpus\r\n",
                "    corpus.append(review)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Creating Bag of Words model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "source": [
                "cv = CountVectorizer(max_features=160)\r\n",
                "X = cv.fit_transform(corpus).toarray()\r\n",
                "y = df.score #prediction on the review rating"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Creating a pickle file for the CountVectorizer model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "source": [
                "joblib.dump(cv, \"assets/cv.pkl\")"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "['assets/cv1.pkl']"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 82
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Model Building"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(\r\n",
                "    X, y, test_size=0.3, random_state=42)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Fitting Naive Bayes to the Training set"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "source": [
                "classifier = MultinomialNB(alpha=0.2)\r\n",
                "classifier.fit(X_train, y_train)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "MultinomialNB(alpha=0.2)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 76
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Creating a pickle file for the Multinomial Naive Bayes model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "source": [
                "joblib.dump(classifier, \"assets/model.pkl\")"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "['model.pkl']"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 77
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit"
        },
        "interpreter": {
            "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}